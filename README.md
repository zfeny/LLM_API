# LLM API ç»Ÿä¸€å°è£…æ¡†æ¶

ä¸€ä¸ªè½»é‡ã€çµæ´»ã€ç”Ÿäº§çº§çš„å¤§è¯­è¨€æ¨¡å‹ API å°è£…æ¡†æ¶ï¼Œæ”¯æŒå¤šç§ LLM æä¾›å•†ï¼Œæä¾›ç»Ÿä¸€çš„ YAML é…ç½®æ¥å£ã€‚

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

- **ğŸ¨ ç»Ÿä¸€æ¥å£**ï¼šä¸€å¥— YAML è¯­æ³•é€‚é…å¤šä¸ª LLM æä¾›å•†
- **âš¡ è½»é‡é«˜æ•ˆ**ï¼šç²¾ç®€ä»£ç ï¼Œé›¶å†—ä½™ä¾èµ–
- **ğŸ”„ ç”Ÿäº§å°±ç»ª**ï¼šè‡ªåŠ¨é‡è¯•ã€ä½¿ç”¨é‡è¿½è¸ªã€æ‰¹é‡å†™å…¥
- **ğŸ›¡ï¸ ç±»å‹å®‰å…¨**ï¼šå®Œæ•´ç±»å‹æ³¨è§£ï¼ŒIDE å‹å¥½
- **ğŸ“Š å¯è§‚æµ‹æ€§**ï¼šè‡ªåŠ¨è®°å½• API è°ƒç”¨å’Œä½¿ç”¨é‡
- **ğŸ§© æ¨¡å—åŒ–è®¾è®¡**ï¼šç‹¬ç«‹æ¨¡å—ï¼ŒæŒ‰éœ€å¯¼å…¥

---

## ğŸ“¦ æ”¯æŒçš„ LLM æä¾›å•†

| æä¾›å•† | æ¨¡å—å | ç‰¹è‰²åŠŸèƒ½ | æ–‡æ¡£ |
|-------|--------|---------|------|
| **Google Gemini** | `gemini` | æ€è€ƒæ¨¡å¼ã€å¤šæ¨¡æ€å›¾ç‰‡ç†è§£ | [ğŸ“– æŸ¥çœ‹æ–‡æ¡£](docs/gemini.md) |
| **OpenAI å…¼å®¹** | `openai` | å¼‚æ­¥å¹¶å‘ã€é€šç”¨å…¼å®¹ | [ğŸ“– æŸ¥çœ‹æ–‡æ¡£](docs/openai.md) |

> **OpenAI å…¼å®¹**æ¨¡å—æ”¯æŒæ‰€æœ‰éµå¾ª OpenAI API è§„èŒƒçš„æœåŠ¡ï¼šOpenAI å®˜æ–¹ã€Azure OpenAIã€æœ¬åœ°éƒ¨ç½²æœåŠ¡ç­‰

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
git clone https://github.com/yourusername/LLM_API.git
cd LLM_API
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
# Gemini API
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash

# OpenAI å…¼å®¹ API
LLM_API_KEY=your_openai_api_key_here
LLM_API_BASE=https://api.openai.com/v1
LLM_MODEL=gpt-4
```

### 3. ä½¿ç”¨ç¤ºä¾‹

#### Gemini æ¨¡å—

```python
from gemini import LLMClient, load_env_file

load_env_file()
client = LLMClient.from_env()

yaml_prompt = """
messages:
  - system: ä½ æ˜¯ä¸€ä¸ªhelpful assistantã€‚
  - user: ä»‹ç»ä¸€ä¸‹Pythonçš„ç‰¹ç‚¹ã€‚
generation:
  model: gemini-2.5-flash
"""

response = client.invoke_from_yaml(yaml_prompt)
print(response)
```

#### OpenAI å…¼å®¹æ¨¡å—

```python
from openai import LLMClient, load_env_file

load_env_file()
client = LLMClient.from_env()

yaml_prompt = """
messages:
  - user: ç”¨Markdownæ€»ç»“Pythonçš„æ ¸å¿ƒä¼˜åŠ¿ã€‚
generation:
  model: gpt-4
  format: markdown
"""

response = client.invoke_from_yaml(yaml_prompt)
print(response)
```

---

## âœ¨ ä¸»è¦åŠŸèƒ½

### ç»Ÿä¸€çš„ YAML é…ç½®

```yaml
messages:
  - system: ç³»ç»Ÿæç¤ºè¯
  - user: ç”¨æˆ·æ¶ˆæ¯
generation:
  model: gemini-2.5-flash
  temperature: 0.7
  max_output_tokens: 2048
  format: markdown  # å¯é€‰ï¼šæ ¼å¼åŒ–è¾“å‡º
```

### æ€è€ƒæ¨¡å¼ï¼ˆGemini ä¸“å±ï¼‰

```yaml
generation:
  model: gemini-2.5-flash
  think: -1  # å¯ç”¨æ·±åº¦æ€è€ƒ
```

### å¤šæ¨¡æ€å›¾ç‰‡ç†è§£ï¼ˆGemini ä¸“å±ï¼‰

```yaml
messages:
  - user: æè¿°è¿™å¼ å›¾ç‰‡ã€‚
    images:
      - path/to/image.jpg
generation:
  model: gemini-2.5-flash
```

### æ ¼å¼åŒ–è¾“å‡º

æ”¯æŒ Markdownã€JSONã€JSON Schema ä¸‰ç§æ ¼å¼ï¼š

```yaml
generation:
  format:
    type: json_schema
    json_schema:
      name: UserInfo
      schema:
        type: object
        properties:
          name: {type: string}
          age: {type: integer}
```

### è‡ªåŠ¨ä½¿ç”¨é‡è¿½è¸ª

æ‰€æœ‰ API è°ƒç”¨è‡ªåŠ¨è®°å½•åˆ° SQLite æ•°æ®åº“ï¼š

```python
from gemini import UsageRecorder

recorder = UsageRecorder()
records = recorder.get_all_records()

for record in records:
    print(f"æ¨¡å‹: {record['model']}, Token: {record['total_tokens']}")
```

---

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- **[Gemini æ¨¡å—å®Œæ•´æŒ‡å—](docs/gemini.md)** - æ€è€ƒæ¨¡å¼ã€å¤šæ¨¡æ€ã€Files API
- **[OpenAI å…¼å®¹æ¨¡å—æŒ‡å—](docs/openai.md)** - å¼‚æ­¥å¹¶å‘ã€è‡ªå®šä¹‰é…ç½®
- **[OpenList å¼€å‘è§„èŒƒ](docs/openlist.md)** - é¡¹ç›®å¼€å‘æµç¨‹

---

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
LLM_API/
â”œâ”€â”€ llm/                # å…¬å…±åŸºç±»ä¸å…±äº«å·¥å…·ï¼ˆå« preset_module/ èµ„æºï¼‰
â”œâ”€â”€ gemini/             # Gemini åŸç”Ÿ API å°è£…
â”œâ”€â”€ openai/             # OpenAI å…¼å®¹ API å°è£…
â”œâ”€â”€ docs/                    # è¯¦ç»†æ–‡æ¡£
â”œâ”€â”€ test_run_gemini.py       # Gemini æµ‹è¯•ç¤ºä¾‹
â”œâ”€â”€ test_run.py              # OpenAI æµ‹è¯•ç¤ºä¾‹
â””â”€â”€ README.md                # æœ¬æ–‡ä»¶
```

### ä¸‰å±‚æ¶æ„

```
YAML è¾“å…¥ â†’ Parser â†’ ICS ä¸­é—´å±‚ â†’ Adapter â†’ SDK
```

---

## ğŸ“ å…¸å‹åœºæ™¯

### ä»£ç ç”Ÿæˆ

```python
yaml_prompt = """
messages:
  - system: ä½ æ˜¯Pythonä¸“å®¶ã€‚
  - user: ç¼–å†™æ–æ³¢é‚£å¥‘å‡½æ•°ï¼Œä½¿ç”¨åŠ¨æ€è§„åˆ’ã€‚
generation:
  model: gemini-2.5-flash
  format: markdown
"""
```

### å›¾ç‰‡åˆ†æ

```python
yaml_prompt = """
messages:
  - user: è¯†åˆ«å›¾ç‰‡ä¸­çš„ç‰©ä½“ã€‚
    images: [photo.jpg]
generation:
  model: gemini-2.5-flash
  format:
    type: json_schema
    json_schema:
      name: ImageAnalysis
      schema:
        type: object
        properties:
          objects: {type: array}
          scene: {type: string}
"""
```

### é«˜å¹¶å‘æœåŠ¡

```python
from openai import AsyncLLMClient

async def process_batch(prompts):
    client = AsyncLLMClient.from_env()
    tasks = [client.invoke_from_yaml(p) for p in prompts]
    return await asyncio.gather(*tasks)
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### é‡è¯•é…ç½®

```python
from gemini import RetryConfig

retry_config = RetryConfig(
    max_retries=5,
    initial_delay=1.0,
    exponential_base=2.0
)
client = LLMClient.from_env(retry_config=retry_config)
```

### ä½¿ç”¨é‡è®°å½•

```python
from gemini import UsageRecorder

recorder = UsageRecorder(
    db_path="custom_usage.db",
    batch_size=20
)
client = LLMClient.from_env(recorder=recorder)
```

---

## ğŸ› å¸¸è§é—®é¢˜

### å¦‚ä½•é€‰æ‹©æ¨¡å—ï¼Ÿ

- **Gemini åŸç”Ÿ**ï¼šéœ€è¦æ€è€ƒæ¨¡å¼ã€å¤šæ¨¡æ€ç­‰ Gemini ä¸“å±åŠŸèƒ½
- **OpenAI å…¼å®¹**ï¼šä½¿ç”¨ OpenAI API æˆ–éœ€è¦å¼‚æ­¥å¹¶å‘

### ä¸¤ä¸ªæ¨¡å—èƒ½åŒæ—¶ä½¿ç”¨å—ï¼Ÿ

å¯ä»¥ï¼Œå®Œå…¨ç‹¬ç«‹ï¼š

```python
from gemini import LLMClient as GeminiClient
from openai import LLMClient as OpenAIClient
```

### å¦‚ä½•è¿ç§»ä»£ç ï¼Ÿ

åªéœ€æ›´æ”¹å¯¼å…¥è¯­å¥ï¼ŒYAML æ ¼å¼åŸºæœ¬å…¼å®¹ã€‚

è¯¦ç»†é—®é¢˜è¯·æŸ¥çœ‹å„æ¨¡å—æ–‡æ¡£ã€‚

---

## ğŸ“Š æ€§èƒ½ç‰¹æ€§

| ç‰¹æ€§ | æ•ˆæœ |
|------|------|
| æ‰¹é‡å†™å…¥ | å‡å°‘ 90% æ•°æ®åº“è¿æ¥ |
| å¼‚æ­¥ I/O | é«˜å¹¶å‘ 8x æ€§èƒ½æå‡ |
| è‡ªåŠ¨é‡è¯• | æˆåŠŸç‡ +80% |
| æ–‡ä»¶ç¼“å­˜ | é¿å…é‡å¤ä¸Šä¼  |

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### v2.0.0 (2025-10-28)

- âœ… æ·»åŠ  Gemini åŸç”Ÿå°è£…æ¨¡å—
- âœ… æ€è€ƒæ¨¡å¼ã€å¤šæ¨¡æ€å›¾ç‰‡ç†è§£
- âœ… Files API é›†æˆ
- ğŸ”„ æ¨¡å—åŒ–é‡æ„

### v1.0.0 (2025-10-27)

- âœ… OpenAI å…¼å®¹å°è£…
- âœ… å¼‚æ­¥å®¢æˆ·ç«¯ã€è‡ªåŠ¨é‡è¯•
- âœ… ä½¿ç”¨é‡è¿½è¸ª

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ï¼š`git checkout -b feature/xxx`
3. æäº¤æ›´æ”¹ï¼š`git commit -m 'Add xxx'`
4. æ¨é€åˆ†æ”¯ï¼š`git push origin feature/xxx`
5. åˆ›å»º Pull Request

è¯¦ç»†å¼€å‘è§„èŒƒè¯·æŸ¥çœ‹ [OpenList æ–‡æ¡£](docs/openlist.md)ã€‚

---

## ğŸ“„ License

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

---

## ğŸ™ è‡´è°¢

- [OpenAI Python SDK](https://github.com/openai/openai-python)
- [Google Generative AI Python SDK](https://github.com/google/generative-ai-python)
- [PyYAML](https://github.com/yaml/pyyaml)

---

**Happy Coding! ğŸš€**
